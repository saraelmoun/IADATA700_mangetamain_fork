from __future__ import annotations

"""Page de clustering des ingr√©dients bas√©e sur la co-occurrence."""

from typing import Optional

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from core.data_loader import DataLoader
from core.ingredients_analyzer import IngredientsAnalyzer
from core.logger import get_logger


class IngredientsClusteringPage:
    """Page pour l'analyse de clustering des ingr√©dients."""
    
    def __init__(self, default_recipes_path: str = "data/RAW_recipes.csv"):
        """
        Initialise la page de clustering.
        
        Args:
            default_recipes_path: Chemin par d√©faut vers le fichier de recettes
        """
        self.default_recipes_path = default_recipes_path
        self.logger = get_logger()
        self.logger.info("Initializing IngredientsClusteringPage")
    
    @st.cache_data
    def _load_and_prepare_data(_self):
        """Charge automatiquement le dataset au d√©marrage."""
        try:
            data_loader = DataLoader(_self.default_recipes_path)
            data = data_loader.load_data()
            return data
        except Exception as e:
            st.error(f"Erreur lors du chargement des donn√©es : {e}")
            return None
    
    def _render_cache_controls(self, analyzer: IngredientsAnalyzer):
        """Render cache management controls in sidebar."""
        st.sidebar.markdown("---")
        st.sidebar.markdown("### Cache Management")
        
        # Get cache info
        cache_info = analyzer.get_cache_info()
        
        # Cache status
        cache_enabled = cache_info["cache_enabled"]
        cache_exists = cache_info["cache_exists"]
        
        if cache_enabled:
            if cache_exists:
                st.sidebar.success("Cache disponible")
                # Show cache details
                if "cache_age_minutes" in cache_info:
                    age_str = f"{cache_info['cache_age_minutes']:.1f} min"
                    size_str = f"{cache_info['cache_size_mb']:.1f} MB"
                    st.sidebar.info(f"Age: {age_str}, Taille: {size_str}")
            else:
                st.sidebar.info("Cache sera cr√©√© apr√®s traitement")
                
            # Cache management buttons
            col1, col2 = st.sidebar.columns(2)
            with col1:
                if st.button("üóëÔ∏è Clear Cache", help="Supprimer tous les fichiers de cache", key="clear_ingredients_cache"):
                    from core.cache_manager import get_cache_manager
                    cache_manager = get_cache_manager()
                    deleted_files = cache_manager.clear(analyzer_name="ingredients")
                    if deleted_files > 0:
                        st.sidebar.success(f"Cache effac√©! ({deleted_files} fichiers)")
                        st.rerun()
                    else:
                        st.sidebar.info("Aucun fichier de cache √† supprimer")
            
            with col2:
                if st.button("‚ÑπÔ∏è Info Cache", help="Afficher les d√©tails du cache", key="info_ingredients_cache"):
                    st.sidebar.json(cache_info)
                    
            # Show total cache files
            if cache_info["cache_files_count"] > 0:
                st.sidebar.caption(f"üìÅ {cache_info['cache_files_count']} fichier(s) de cache")
        else:
            st.sidebar.warning("Cache d√©sactiv√©")
    
    def render_sidebar(self) -> dict:
        """
        Affiche la sidebar avec les param√®tres de clustering.
        
        Returns:
            Dictionnaire avec les param√®tres s√©lectionn√©s
        """
        st.sidebar.header("üîß Param√®tres de Clustering")
        
        # Param√®tres de clustering
        n_ingredients = st.sidebar.slider(
            "Nombre d'ingr√©dients √† analyser",
            min_value=10,
            max_value=200,
            value=50,
            step=10,
            help="Nombre d'ingr√©dients les plus fr√©quents √† inclure dans l'analyse"
        )
        
        n_clusters = st.sidebar.slider(
            "Nombre de clusters",
            min_value=2,
            max_value=20,
            value=5,
            step=1,
            help="Nombre de groupes d'ingr√©dients √† cr√©er"
        )
        
        # Param√®tres t-SNE
        st.sidebar.subheader("üé® Param√®tres Visualisation")
        tsne_perplexity = st.sidebar.slider(
            "Perplexit√© t-SNE",
            min_value=5,
            max_value=50,
            value=30,
            step=5,
            help="Contr√¥le la densit√© des groupes dans la visualisation"
        )
        
        # Bouton d'analyse dans la sidebar
        analyze_button = st.sidebar.button("üöÄ Lancer l'analyse", type="primary")
        
        return {
            "n_ingredients": n_ingredients,
            "n_clusters": n_clusters,
            "tsne_perplexity": tsne_perplexity,
            "analyze_button": analyze_button
        }
    
    def render_cooccurrence_analysis(self, ingredient_names: list, ingredients_matrix: pd.DataFrame) -> None:
        """
        Affiche l'analyse de co-occurrence interactive.
        
        Args:
            ingredient_names: Liste des noms d'ingr√©dients
            ingredients_matrix: Matrice de co-occurrence
        """
        st.subheader("üîç Analyse de Co-occurrence")
        
        # Cr√©ation de trois colonnes pour les menus d√©roulants
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            ingredient1 = st.selectbox(
                "Premier ingr√©dient",
                options=ingredient_names,
                index=0,
                key="ingredient1"
            )
        
        with col2:
            ingredient2 = st.selectbox(
                "Deuxi√®me ingr√©dient",
                options=ingredient_names,
                index=1 if len(ingredient_names) > 1 else 0,
                key="ingredient2"
            )
        
        # Afficher le score de co-occurrence
        if ingredient1 and ingredient2 and ingredient1 != ingredient2:
            try:
                # R√©cup√©rer le score de co-occurrence
                cooccurrence_score = ingredients_matrix.at[ingredient1, ingredient2]
                
                # Calculer les statistiques de la matrice
                matrix_values = ingredients_matrix.values
                matrix_values_flat = matrix_values[matrix_values > 0]  # Seulement les valeurs non-nulles
                
                if len(matrix_values_flat) > 0:
                    max_score = np.max(matrix_values_flat)
                    avg_score = np.mean(matrix_values_flat)
                    median_score = np.median(matrix_values_flat)
                else:
                    max_score = avg_score = median_score = 0
                
                # Affichage des m√©triques
                col_metric1, col_metric2, col_metric3 = st.columns(3)
                
                with col_metric1:
                    st.metric(
                        label="Score de co-occurrence",
                        value=f"{cooccurrence_score:.0f}",
                        help=f"Nombre de recettes contenant '{ingredient1}' ET '{ingredient2}'"
                    )
                
                with col_metric2:
                    if max_score > 0:
                        percentile = (cooccurrence_score / max_score) * 100
                        st.metric(
                            label="Percentile",
                            value=f"{percentile:.1f}%",
                            help="Position par rapport au score maximum"
                        )
                
                with col_metric3:
                    if avg_score > 0:
                        ratio_avg = cooccurrence_score / avg_score
                        st.metric(
                            label="Ratio vs Moyenne",
                            value=f"{ratio_avg:.1f}x",
                            help=f"Ratio par rapport √† la moyenne ({avg_score:.1f})"
                        )
                
                # Barre de progression visuelle
                if max_score > 0:
                    normalized_score = cooccurrence_score / max_score
                    st.progress(normalized_score)
                    
                    # Interpr√©tation du score
                    if cooccurrence_score >= median_score * 2:
                        st.success("üî• Combinaison tr√®s fr√©quente!")
                    elif cooccurrence_score >= median_score:
                        st.info("‚úÖ Combinaison courante")
                    elif cooccurrence_score > 0:
                        st.warning("‚ö†Ô∏è Combinaison rare")
                    else:
                        st.error("‚ùå Aucune co-occurrence trouv√©e")
                
            except (ValueError, IndexError, KeyError):
                st.warning("Erreur lors du calcul du score de co-occurrence")
    
    def render_clusters(self, clusters: np.ndarray, ingredient_names: list, n_clusters: int) -> None:
        """
        Affiche les clusters d'ingr√©dients.
        
        Args:
            clusters: Labels des clusters
            ingredient_names: Liste des noms d'ingr√©dients
            n_clusters: Nombre de clusters
        """
        st.subheader("üéØ Clusters d'Ingr√©dients")
        
        # Affichage par cluster avec couleurs
        colors = ["üî¥", "üü†", "üü°", "üü¢", "üîµ", "üü£", "‚ö´", "‚ö™", "üü§", "üîò"]
        
        for cluster_id in range(n_clusters):
            cluster_ingredients = [
                ingredient_names[i] for i, cluster in enumerate(clusters) 
                if cluster == cluster_id
            ]
            
            color_emoji = colors[cluster_id % len(colors)]
            
            with st.expander(
                f"{color_emoji} Cluster {cluster_id + 1} ({len(cluster_ingredients)} ingr√©dients)", 
                expanded=True
            ):
                # Affichage en colonnes pour une meilleure lisibilit√©
                cols = st.columns(4)
                for i, ingredient in enumerate(cluster_ingredients):
                    cols[i % 4].write(f"‚Ä¢ **{ingredient}**")
    
    def render_tsne_visualization(self, analyzer: IngredientsAnalyzer, clusters: np.ndarray, tsne_perplexity: int) -> None:
        """
        Affiche la visualisation t-SNE.
        
        Args:
            analyzer: Instance de l'analyseur d'ingr√©dients
            clusters: Labels des clusters
            tsne_perplexity: Param√®tre de perplexit√© pour t-SNE
        """
        col_title, col_button = st.columns([3, 1])
        with col_title:
            st.subheader("üé® Visualisation t-SNE 2D des Clusters")
        with col_button:
            regenerate_tsne = st.button("üîÑ R√©g√©n√©rer t-SNE", help="Reg√©n√©rer la visualisation avec de nouveaux param√®tres")
        
        # G√©n√©rer t-SNE au premier lancement ou si demand√©
        should_generate_tsne = 'tsne_data' not in st.session_state or regenerate_tsne
        
        if should_generate_tsne:
            with st.spinner("G√©n√©ration de la visualisation t-SNE..."):
                tsne_data = analyzer.generate_tsne_visualization(clusters, perplexity=tsne_perplexity)
                st.session_state['tsne_data'] = tsne_data
        else:
            tsne_data = st.session_state['tsne_data']
        
        if "error" not in tsne_data:
            # Cr√©er le graphique de dispersion avec Plotly
            fig_tsne = go.Figure()
            
            # Palette de couleurs hexad√©cimales pour t-SNE
            tsne_colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7", 
                          "#DDA0DD", "#98D8C8", "#F7DC6F", "#BB8FCE", "#85C1E9"]
            
            n_clusters = tsne_data['n_clusters']
            
            # Ajouter les points par cluster pour avoir des couleurs distinctes
            for cluster_id in range(n_clusters):
                # Filtrer les donn√©es pour ce cluster
                cluster_mask = [label == cluster_id for label in tsne_data['cluster_labels']]
                cluster_x = [x for i, x in enumerate(tsne_data['x_coords']) if cluster_mask[i]]
                cluster_y = [y for i, y in enumerate(tsne_data['y_coords']) if cluster_mask[i]]
                cluster_names = [name for i, name in enumerate(tsne_data['ingredient_names']) if cluster_mask[i]]
                
                color = tsne_colors[cluster_id % len(tsne_colors)]
                
                fig_tsne.add_trace(go.Scatter(
                    x=cluster_x,
                    y=cluster_y,
                    mode='markers+text',
                    marker=dict(
                        size=12,
                        color=color,
                        line=dict(width=2, color='white'),
                        opacity=0.8
                    ),
                    text=cluster_names,
                    textposition="top center",
                    textfont=dict(size=10),
                    name=f"Cluster {cluster_id + 1}",
                    hovertemplate="<b>%{text}</b><br>Cluster: " + f"{cluster_id + 1}<br>" +
                                  "Coordonn√©es: (%{x:.2f}, %{y:.2f})<extra></extra>"
                ))
            
            # Mise en forme du graphique
            fig_tsne.update_layout(
                title="Visualisation t-SNE des Ingr√©dients par Cluster",
                xaxis_title="Dimension t-SNE 1",
                yaxis_title="Dimension t-SNE 2",
                showlegend=True,
                height=600,
                hovermode='closest',
                plot_bgcolor='rgba(245,245,245,0.8)',
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1
                )
            )
            
            # Afficher le graphique
            st.plotly_chart(fig_tsne, use_container_width=True)
            
            # Informations sur t-SNE
            with st.expander("‚ÑπÔ∏è √Ä propos de la visualisation t-SNE"):
                st.markdown("""
                **t-SNE (t-Distributed Stochastic Neighbor Embedding)** est une technique de r√©duction de dimensionnalit√© 
                qui permet de visualiser des donn√©es haute-dimensionnelles en 2D.
                
                **Dans ce contexte :**
                - Chaque point repr√©sente un **ingr√©dient**
                - La position est bas√©e sur les **profils de co-occurrence** avec les autres ingr√©dients
                - Les couleurs correspondent aux **clusters K-means**
                - Les ingr√©dients proches ont des **patterns de co-occurrence similaires**
                
                **Interpr√©tation :**
                - Points regroup√©s = ingr√©dients utilis√©s dans des contextes similaires
                - Clusters color√©s = groupes d√©tect√©s par l'algorithme K-means
                - Distance = mesure de similarit√© des profils culinaires
                """)
                
                st.markdown(f"""
                **Param√®tres utilis√©s :**
                - Perplexit√© : {tsne_data['tsne_params']['perplexity']}
                - It√©rations max : {tsne_data['tsne_params']['max_iter']}
                - Seed al√©atoire : {tsne_data['tsne_params']['random_state']}
                """)
        else:
            st.error("Erreur lors de la g√©n√©ration de la visualisation t-SNE")
    
    def render_sidebar_statistics(self, clusters: Optional[np.ndarray], ingredient_names: Optional[list]) -> None:
        """
        Affiche les statistiques dans la sidebar.
        
        Args:
            clusters: Labels des clusters (optionnel)
            ingredient_names: Liste des noms d'ingr√©dients (optionnel)
        """
        if clusters is not None and ingredient_names is not None:
            st.sidebar.markdown("---")
            st.sidebar.markdown("### üìä Statistiques")
            
            # Comptage par cluster
            cluster_counts = pd.Series(clusters).value_counts().sort_index()
            
            st.sidebar.metric("Total ingr√©dients", len(ingredient_names))
            st.sidebar.metric("Nombre de clusters", len(cluster_counts))
            
            # Graphique horizontal des proportions par cluster
            st.sidebar.markdown("**R√©partition par cluster:**")
            
            # Cr√©er le graphique avec Plotly
            colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7", "#DDA0DD", "#98D8C8", "#F7DC6F", "#BB8FCE", "#85C1E9"]
            
            fig = go.Figure()
            
            for i, count in enumerate(cluster_counts):
                percentage = (count / len(ingredient_names)) * 100
                color = colors[i % len(colors)]
                
                fig.add_trace(go.Bar(
                    x=[count],
                    y=[f"Cluster {i+1}"],
                    orientation='h',
                    name=f"Cluster {i+1}",
                    marker_color=color,
                    text=f"{count} ({percentage:.1f}%)",
                    textposition="outside",
                    showlegend=False
                ))
            
            fig.update_layout(
                title="",
                xaxis_title="Nombre d'ingr√©dients",
                yaxis_title="",
                height=min(400, len(cluster_counts) * 40 + 100),
                margin=dict(l=10, r=10, t=10, b=10),
                font=dict(size=10)
            )
            
            st.sidebar.plotly_chart(fig, use_container_width=True)
    
    def render_analysis_summary(self, analyzer: IngredientsAnalyzer) -> None:
        """
        Affiche le r√©sum√© de l'analyse.
        
        Args:
            analyzer: Instance de l'analyseur d'ingr√©dients
        """
        # Afficher quelques exemples de regroupements d'ingr√©dients
        if hasattr(analyzer, 'ingredient_groups') and analyzer.ingredient_groups:
            with st.expander("üîó Exemples de regroupements d'ingr√©dients similaires"):
                # Afficher les groupes avec plus d'un √©l√©ment
                multi_groups = [g for g in analyzer.ingredient_groups if len(g) > 1]
                
                if multi_groups:
                    # Afficher les 10 premiers groupes
                    for i, group in enumerate(multi_groups[:10]):
                        members_display = ' | '.join(group[:5])
                        if len(group) > 5:
                            members_display += f" (+ {len(group)-5} autres)"
                        st.write(f"**Groupe {i+1}:** {members_display}")
                    
                    st.info(f"Total: {len(multi_groups)} groupes d'ingr√©dients similaires d√©tect√©s")
                    
                    # Debug pour des ingr√©dients probl√©matiques
                    debug_info = analyzer.debug_ingredient_mapping(['pepper', 'egg', 'salt', 'butter', 'onion'])
                    if 'search_results' in debug_info:
                        st.write("**üîç Debug - Exemples de normalisation:**")
                        for term, matches in debug_info['search_results'].items():
                            if matches:
                                st.write(f"*{term.title()}:*")
                                for match in matches[:3]:  # Limiter √† 3 r√©sultats
                                    # Montrer aussi la normalisation
                                    normalized = analyzer.normalize_ingredient(match['ingredient'])
                                    status = "‚úÖ Repr√©sentant" if match['is_representative'] else f"‚û°Ô∏è Mapp√© vers '{match['representative']}'"
                                    st.write(f"  ‚Ä¢ `{match['ingredient']}` ‚Üí `{normalized}` {status}")
                    
                    # Exemple de normalisation en temps r√©el
                    st.write("**üß™ Test de normalisation:**")
                    test_ingredients = [
                        "large eggs", "fresh ground black pepper", "unsalted butter", 
                        "red onions", "whole milk", "extra virgin olive oil"
                    ]
                    for ing in test_ingredients:
                        normalized = analyzer.normalize_ingredient(ing)
                        st.write(f"‚Ä¢ `{ing}` ‚Üí `{normalized}`")
                    
                    # R√©sum√© complet du processus
                    with st.expander("üìã R√©sum√© Complet du Data Processing"):
                        summary = analyzer.get_processing_summary()
                        if "error" not in summary:
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.write("**üìä Donn√©es d'entr√©e:**")
                                st.write(f"‚Ä¢ Recettes: {summary['input_data']['total_recipes']:,}")
                                st.write(f"‚Ä¢ Ingr√©dients bruts: {summary['input_data']['total_raw_ingredients']:,}")
                                st.write(f"‚Ä¢ Moyenne par recette: {summary['input_data']['avg_ingredients_per_recipe']}")
                                
                                st.write("**üîÑ Normalisation:**")
                                st.write(f"‚Ä¢ Ingr√©dients uniques bruts: {summary['normalization']['total_unique_raw']:,}")
                                st.write(f"‚Ä¢ Apr√®s normalisation: {summary['normalization']['total_normalized']:,}")
                                st.write(f"‚Ä¢ R√©duction: {summary['normalization']['reduction_ratio']}%")
                            
                            with col2:
                                st.write("**üîó Regroupement:**")
                                st.write(f"‚Ä¢ Groupes multiples: {summary['grouping']['groups_with_multiple_items']}")
                                st.write(f"‚Ä¢ Plus grand groupe: {summary['grouping']['largest_group_size']} √©l√©ments")
                                
                                st.write("**üìà Matrice Co-occurrence:**")
                                st.write(f"‚Ä¢ Dimensions: {summary['cooccurrence_matrix']['dimensions']}")
                                st.write(f"‚Ä¢ Co-occurrences: {summary['cooccurrence_matrix']['total_cooccurrences']:,}")
                                st.write(f"‚Ä¢ Paires non-nulles: {summary['cooccurrence_matrix']['non_zero_pairs']:,}")
                                st.write(f"‚Ä¢ Sparsit√©: {summary['cooccurrence_matrix']['sparsity']}%")
                else:
                    st.warning("Aucun regroupement d√©tect√©. Tous les ingr√©dients sont consid√©r√©s comme uniques.")
    
    def run(self) -> None:
        """Point d'entr√©e principal de la page."""
        self.logger.info("Starting ingredients clustering analysis")
        st.markdown("---")
        
        # Chargement automatique des donn√©es
        self.logger.debug("Loading and preparing data")
        data = self._load_and_prepare_data()
        
        # Sidebar pour les param√®tres
        params = self.render_sidebar()
        self.logger.debug(f"Clustering parameters: {params}")
        
        # Zone principale
        st.header("üìà Analyse des donn√©es")
        
        # Traitement des donn√©es
        if data is not None:
            self.logger.info(f"Dataset loaded successfully: {len(data)} recipes")
            st.success(f"Dataset charg√© : {len(data)} recettes")
            
            # Initialisation de l'analyseur
            analyzer = IngredientsAnalyzer(data)
            
            # Cache controls dans la sidebar
            self._render_cache_controls(analyzer)
            
            # Lancer l'analyse automatiquement ou avec le bouton
            if params["analyze_button"] or 'ingredient_names' not in st.session_state:
                self.logger.info("Starting clustering analysis with parameters")
                with st.spinner("Analyse en cours..."):
                    # Traitement des ingr√©dients
                    self.logger.debug(f"Processing ingredients with n_ingredients={params['n_ingredients']}")
                    ingredients_matrix, ingredient_names = analyzer.process_ingredients(params["n_ingredients"])
                    self.logger.info(f"Processed ingredients matrix: {ingredients_matrix.shape}")
                    
                    # Clustering
                    self.logger.debug(f"Performing clustering with n_clusters={params['n_clusters']}")
                    clusters = analyzer.perform_clustering(ingredients_matrix, params["n_clusters"])
                    self.logger.info(f"Clustering completed: {len(set(clusters))} unique clusters found")
                    
                    # Sauvegarde des r√©sultats dans la session
                    st.session_state['ingredient_names'] = ingredient_names
                    st.session_state['clusters'] = clusters
                    st.session_state['ingredients_matrix'] = ingredients_matrix
                    st.session_state['analyzer'] = analyzer
                    
                self.logger.info("Analysis completed successfully")
                st.success("Analyse termin√©e!")
                
                # Afficher le r√©sum√© de l'analyse
                self.render_analysis_summary(analyzer)
            
            # Affichage des r√©sultats si disponibles
            if 'ingredient_names' in st.session_state:
                self.logger.debug("Displaying cached clustering results")
                ingredient_names = st.session_state['ingredient_names']
                ingredients_matrix = st.session_state['ingredients_matrix']
                clusters = st.session_state['clusters']
                analyzer = st.session_state['analyzer']
                
                # Analyse de co-occurrence
                self.render_cooccurrence_analysis(ingredient_names, ingredients_matrix)
                
                # Affichage des clusters
                self.render_clusters(clusters, ingredient_names, params["n_clusters"])
                
                # Visualisation t-SNE
                self.render_tsne_visualization(analyzer, clusters, params["tsne_perplexity"])
                
                # Statistiques dans la sidebar
                self.render_sidebar_statistics(clusters, ingredient_names)
        
        else:
            st.error("Impossible de charger les donn√©es. V√©rifiez la pr√©sence du fichier de donn√©es.")
        
        # Informations dans la sidebar
        with st.sidebar:
            st.markdown("---")
            
            with st.expander("‚ÑπÔ∏è √Ä propos de l'analyse"):
                st.markdown("""
                **Analyseur de Recettes Food.com**
                
                üéØ **Objectif** : Identifier des groupes d'ingr√©dients qui apparaissent fr√©quemment ensemble
                
                üìä **M√©thodes** :
                - Preprocessing des ingr√©dients
                - Matrice de co-occurrence
                - Clustering K-means
                - Visualisation interactive
                
                üí° **Utilisation** :
                1. Ajustez les param√®tres
                2. Lancez l'analyse
                3. Explorez les clusters
                4. Analysez les co-occurrences
                """)
        
        # Footer
        st.markdown("---")
        st.markdown("üç≥ **Clustering d'Ingr√©dients** - D√©velopp√© avec ‚ù§Ô∏è et Streamlit pour l'analyse de recettes Food.com")