from __future__ import annotations

"""Streamlit page: Analyse de co-occurrence et clustering d'ingr√©dients.

Note: La User Story est affich√©e dans l'interface Streamlit (m√©thode run()),
pas dans cette docstring, conform√©ment au pattern de la page 1.
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st

from core.data_loader import DataLoader
from core.ingredients_analyzer import IngredientsAnalyzer
from core.logger import get_logger


@dataclass
class IngredientsClusteringConfig:
    """Configuration pour l'analyse de clustering d'ingr√©dients.

    Attributes:
        recipes_path: Chemin vers le fichier CSV contenant les recettes.
        n_ingredients: Nombre d'ingr√©dients les plus fr√©quents √† analyser.
        n_clusters: Nombre de clusters √† cr√©er avec K-means.
        tsne_perplexity: Param√®tre de perplexit√© pour la visualisation t-SNE.
    """

    recipes_path: Path
    n_ingredients: int = 50
    n_clusters: int = 5
    tsne_perplexity: int = 30


class IngredientsClusteringPage:
    """Page Streamlit pour l'analyse de clustering des ingr√©dients.

    Cette classe g√®re l'interface utilisateur et la logique de pr√©sentation
    pour l'analyse de co-occurrence et le clustering d'ingr√©dients bas√© sur
    leurs patterns d'apparition dans les recettes.

    Attributes:
        default_recipes_path: Chemin par d√©faut vers le fichier de recettes.
        logger: Instance du logger pour le suivi des op√©rations.
    """

    def __init__(self, default_recipes_path: str = "data/RAW_recipes.csv") -> None:
        """Initialise la page de clustering d'ingr√©dients.

        Args:
            default_recipes_path: Chemin par d√©faut vers le fichier CSV des recettes.
                Doit contenir une colonne avec les listes d'ingr√©dients.

        Raises:
            ValueError: Si le chemin fourni est invalide ou vide.
        """
        if not default_recipes_path:
            raise ValueError("Le chemin du fichier de recettes ne peut pas √™tre vide")

        self.default_recipes_path = default_recipes_path
        self.logger = get_logger()
        self.logger.info("Initializing IngredientsClusteringPage")

    @st.cache_data
    def _load_and_prepare_data(_self) -> Optional[pd.DataFrame]:
        """Charge automatiquement le dataset au d√©marrage.

        Cette m√©thode est mise en cache par Streamlit pour √©viter de recharger
        les donn√©es √† chaque interaction utilisateur.

        Returns:
            DataFrame contenant les recettes si le chargement r√©ussit, None sinon.
            Le DataFrame contient au minimum une colonne d'ingr√©dients.

        Raises:
            Exception: Affiche une erreur Streamlit mais ne propage pas l'exception.
        """
        try:
            data_loader = DataLoader(_self.default_recipes_path)
            data = data_loader.load_data()
            return data
        except Exception as e:
            st.error(f"Erreur lors du chargement des donn√©es : {e}")
            return None

    def _render_cache_controls(self, analyzer: IngredientsAnalyzer) -> None:
        """Affiche les contr√¥les de gestion du cache dans la sidebar.

        Permet √† l'utilisateur de visualiser l'√©tat du cache et de le supprimer
        si n√©cessaire. Affiche des m√©triques sur l'√¢ge, la taille et le nombre
        de fichiers en cache.

        Args:
            analyzer: Instance de l'analyseur d'ingr√©dients dont on g√®re le cache.
        """
        st.sidebar.markdown("---")
        st.sidebar.markdown("### Cache Management")

        # Get cache info
        cache_info = analyzer.get_cache_info()

        # Cache status
        cache_enabled = cache_info["cache_enabled"]
        cache_exists = cache_info["cache_exists"]

        if cache_enabled:
            if cache_exists:
                st.sidebar.success("Cache disponible")
                # Show cache details
                if "cache_age_minutes" in cache_info:
                    age_str = f"{cache_info['cache_age_minutes']:.1f} min"
                    size_str = f"{cache_info['cache_size_mb']:.1f} MB"
                    st.sidebar.info(f"Age: {age_str}, Taille: {size_str}")
            else:
                st.sidebar.info("Cache sera cr√©√© apr√®s traitement")

            # Cache management buttons
            col1, col2 = st.sidebar.columns(2)
            with col1:
                if st.button(
                    "üóëÔ∏è Clear Cache",
                    help="Supprimer tous les fichiers de cache",
                    key="clear_ingredients_cache",
                ):
                    from core.cache_manager import get_cache_manager

                    cache_manager = get_cache_manager()
                    deleted_files = cache_manager.clear(analyzer_name="ingredients")
                    if deleted_files > 0:
                        st.sidebar.success(f"Cache effac√©! ({deleted_files} fichiers)")
                        st.rerun()
                    else:
                        st.sidebar.info("Aucun fichier de cache √† supprimer")

            with col2:
                if st.button(
                    "‚ÑπÔ∏è Info Cache",
                    help="Afficher les d√©tails du cache",
                    key="info_ingredients_cache",
                ):
                    st.sidebar.json(cache_info)

            # Show total cache files
            if cache_info["cache_files_count"] > 0:
                st.sidebar.caption(f"üìÅ {cache_info['cache_files_count']} fichier(s) de cache")
        else:
            st.sidebar.warning("Cache d√©sactiv√©")

    def render_sidebar(self) -> dict[str, int | bool]:
        """Affiche la sidebar avec les param√®tres de clustering.

        Cr√©e une interface interactive dans la sidebar permettant √† l'utilisateur
        de configurer les param√®tres de l'analyse de clustering:
        - Nombre d'ingr√©dients √† analyser
        - Nombre de clusters √† cr√©er
        - Param√®tres de visualisation t-SNE

        Returns:
            Dictionnaire contenant les param√®tres s√©lectionn√©s par l'utilisateur:
                - n_ingredients: Nombre d'ingr√©dients les plus fr√©quents (10-200)
                - n_clusters: Nombre de groupes √† cr√©er (2-20)
                - tsne_perplexity: Param√®tre de densit√© pour t-SNE (5-50)
                - analyze_button: True si le bouton d'analyse a √©t√© cliqu√©
        """
        st.sidebar.header("üîß Param√®tres de Clustering")

        # Param√®tres de clustering
        n_ingredients = st.sidebar.slider(
            "Nombre d'ingr√©dients √† analyser",
            min_value=10,
            max_value=200,
            value=50,
            step=10,
            help="Nombre d'ingr√©dients les plus fr√©quents √† inclure dans l'analyse",
        )

        n_clusters = st.sidebar.slider(
            "Nombre de clusters",
            min_value=2,
            max_value=20,
            value=5,
            step=1,
            help="Nombre de groupes d'ingr√©dients √† cr√©er",
        )

        # Param√®tres t-SNE
        st.sidebar.subheader("üé® Param√®tres Visualisation")
        tsne_perplexity = st.sidebar.slider(
            "Perplexit√© t-SNE",
            min_value=5,
            max_value=50,
            value=30,
            step=5,
            help="Contr√¥le la densit√© des groupes dans la visualisation",
        )

        # Bouton d'analyse dans la sidebar
        analyze_button = st.sidebar.button("üöÄ Lancer l'analyse", type="primary")

        return {
            "n_ingredients": n_ingredients,
            "n_clusters": n_clusters,
            "tsne_perplexity": tsne_perplexity,
            "analyze_button": analyze_button,
        }

    def render_cooccurrence_analysis(self, ingredient_names: list[str], ingredients_matrix: pd.DataFrame) -> None:
        """Affiche l'analyse de co-occurrence interactive.

        Permet √† l'utilisateur de s√©lectionner deux ingr√©dients et visualise
        leur score de co-occurrence (nombre de recettes o√π ils apparaissent ensemble).
        Affiche √©galement des statistiques contextuelles pour interpr√©ter le score.

        Args:
            ingredient_names: Liste des noms d'ingr√©dients disponibles pour la s√©lection.
            ingredients_matrix: Matrice de co-occurrence (DataFrame sym√©trique) o√π
                matrix[ing1, ing2] = nombre de recettes contenant ing1 ET ing2.

        Raises:
            ValueError: Si les ingr√©dients s√©lectionn√©s ne sont pas dans la matrice.
            IndexError: Si un acc√®s invalide √† la matrice est tent√©.
        """
        st.subheader("üîç Analyse de Co-occurrence")

        # Cr√©ation de trois colonnes pour les menus d√©roulants
        col1, col2, col3 = st.columns([1, 1, 1])

        with col1:
            ingredient1 = st.selectbox(
                "Premier ingr√©dient",
                options=ingredient_names,
                index=0,
                key="ingredient1",
            )

        with col2:
            ingredient2 = st.selectbox(
                "Deuxi√®me ingr√©dient",
                options=ingredient_names,
                index=1 if len(ingredient_names) > 1 else 0,
                key="ingredient2",
            )

        # Afficher le score de co-occurrence
        if ingredient1 and ingredient2 and ingredient1 != ingredient2:
            try:
                # R√©cup√©rer le score de co-occurrence
                cooccurrence_score = ingredients_matrix.at[ingredient1, ingredient2]

                # Calculer les statistiques de la matrice
                matrix_values = ingredients_matrix.values
                matrix_values_flat = matrix_values[matrix_values > 0]  # Seulement les valeurs non-nulles

                if len(matrix_values_flat) > 0:
                    max_score = np.max(matrix_values_flat)
                    avg_score = np.mean(matrix_values_flat)
                    median_score = np.median(matrix_values_flat)
                else:
                    max_score = avg_score = median_score = 0

                # Affichage des m√©triques
                col_metric1, col_metric2, col_metric3 = st.columns(3)

                with col_metric1:
                    st.metric(
                        label="Score de co-occurrence",
                        value=f"{cooccurrence_score:.0f}",
                        help=f"Nombre de recettes contenant '{ingredient1}' ET '{ingredient2}'",
                    )

                with col_metric2:
                    if max_score > 0:
                        percentile = (cooccurrence_score / max_score) * 100
                        st.metric(
                            label="Percentile",
                            value=f"{percentile:.1f}%",
                            help="Position par rapport au score maximum",
                        )

                with col_metric3:
                    if avg_score > 0:
                        ratio_avg = cooccurrence_score / avg_score
                        st.metric(
                            label="Ratio vs Moyenne",
                            value=f"{ratio_avg:.1f}x",
                            help=f"Ratio par rapport √† la moyenne ({avg_score:.1f})",
                        )

                # Barre de progression visuelle
                if max_score > 0:
                    normalized_score = cooccurrence_score / max_score
                    st.progress(normalized_score)

                    # Interpr√©tation du score
                    if cooccurrence_score >= median_score * 2:
                        st.success("üî• Combinaison tr√®s fr√©quente!")
                    elif cooccurrence_score >= median_score:
                        st.info("‚úÖ Combinaison courante")
                    elif cooccurrence_score > 0:
                        st.warning("‚ö†Ô∏è Combinaison rare")
                    else:
                        st.error("‚ùå Aucune co-occurrence trouv√©e")

            except (ValueError, IndexError, KeyError):
                st.warning("Erreur lors du calcul du score de co-occurrence")

    def render_clusters(self, clusters: np.ndarray, ingredient_names: list[str], n_clusters: int) -> None:
        """Affiche les clusters d'ingr√©dients de mani√®re organis√©e.

        Pr√©sente chaque cluster dans un expander s√©par√© avec une couleur distinctive.
        Les ingr√©dients sont affich√©s en colonnes pour une meilleure lisibilit√©.

        Args:
            clusters: Array numpy contenant les labels de cluster pour chaque ingr√©dient.
                Taille = len(ingredient_names), valeurs de 0 √† n_clusters-1.
            ingredient_names: Liste ordonn√©e des noms d'ingr√©dients correspondant
                aux indices dans l'array clusters.
            n_clusters: Nombre total de clusters cr√©√©s (pour l'it√©ration).

        Example:
            >>> clusters = np.array([0, 1, 0, 2, 1])
            >>> names = ['salt', 'sugar', 'pepper', 'flour', 'honey']
            >>> page.render_clusters(clusters, names, 3)
            # Affiche 3 expanders avec les ingr√©dients regroup√©s
        """
        st.subheader("üéØ Clusters d'Ingr√©dients")

        # Affichage par cluster avec couleurs
        colors = ["üî¥", "üü†", "üü°", "üü¢", "üîµ", "üü£", "‚ö´", "‚ö™", "üü§", "üîò"]

        for cluster_id in range(n_clusters):
            cluster_ingredients = [ingredient_names[i] for i, cluster in enumerate(clusters) if cluster == cluster_id]

            color_emoji = colors[cluster_id % len(colors)]

            with st.expander(
                f"{color_emoji} Cluster {cluster_id + 1} ({len(cluster_ingredients)} ingr√©dients)",
                expanded=True,
            ):
                # Affichage en colonnes pour une meilleure lisibilit√©
                cols = st.columns(4)
                for i, ingredient in enumerate(cluster_ingredients):
                    cols[i % 4].write(f"‚Ä¢ **{ingredient}**")

    def render_tsne_visualization(self, analyzer: IngredientsAnalyzer, clusters: np.ndarray, tsne_perplexity: int) -> None:
        """Affiche la visualisation t-SNE 2D des clusters d'ingr√©dients.

        G√©n√®re et affiche un graphique interactif Plotly montrant les ingr√©dients
        dans un espace 2D obtenu par r√©duction de dimensionnalit√© t-SNE. Les points
        sont color√©s selon leur cluster et peuvent √™tre r√©g√©n√©r√©s avec de nouveaux
        param√®tres.

        Args:
            analyzer: Instance de IngredientsAnalyzer utilis√©e pour g√©n√©rer la
                visualisation t-SNE √† partir de la matrice de co-occurrence.
            clusters: Array numpy des labels de cluster pour chaque ingr√©dient.
            tsne_perplexity: Param√®tre de perplexit√© pour t-SNE (5-50).
                Contr√¥le la densit√© des groupes dans la visualisation.
                Valeurs faibles = focus local, valeurs √©lev√©es = structure globale.

        Notes:
            La visualisation est mise en cache dans st.session_state pour √©viter
            de la recalculer √† chaque interaction. Un bouton permet de forcer la
            r√©g√©n√©ration avec de nouveaux param√®tres al√©atoires.
        """
        col_title, col_button = st.columns([3, 1])
        with col_title:
            st.subheader("üé® Visualisation t-SNE 2D des Clusters")
        with col_button:
            regenerate_tsne = st.button(
                "üîÑ R√©g√©n√©rer t-SNE",
                help="Reg√©n√©rer la visualisation avec de nouveaux param√®tres",
            )

        # G√©n√©rer t-SNE au premier lancement ou si demand√©
        should_generate_tsne = "tsne_data" not in st.session_state or regenerate_tsne

        if should_generate_tsne:
            with st.spinner("G√©n√©ration de la visualisation t-SNE..."):
                tsne_data = analyzer.generate_tsne_visualization(clusters, perplexity=tsne_perplexity)
                st.session_state["tsne_data"] = tsne_data
        else:
            tsne_data = st.session_state["tsne_data"]

        if "error" not in tsne_data:
            # Cr√©er le graphique de dispersion avec Plotly
            fig_tsne = go.Figure()

            # Palette de couleurs hexad√©cimales pour t-SNE
            tsne_colors = [
                "#FF6B6B",
                "#4ECDC4",
                "#45B7D1",
                "#96CEB4",
                "#FFEAA7",
                "#DDA0DD",
                "#98D8C8",
                "#F7DC6F",
                "#BB8FCE",
                "#85C1E9",
            ]

            n_clusters = tsne_data["n_clusters"]

            # Ajouter les points par cluster pour avoir des couleurs distinctes
            for cluster_id in range(n_clusters):
                # Filtrer les donn√©es pour ce cluster
                cluster_mask = [label == cluster_id for label in tsne_data["cluster_labels"]]
                cluster_x = [x for i, x in enumerate(tsne_data["x_coords"]) if cluster_mask[i]]
                cluster_y = [y for i, y in enumerate(tsne_data["y_coords"]) if cluster_mask[i]]
                cluster_names = [name for i, name in enumerate(tsne_data["ingredient_names"]) if cluster_mask[i]]

                color = tsne_colors[cluster_id % len(tsne_colors)]

                fig_tsne.add_trace(
                    go.Scatter(
                        x=cluster_x,
                        y=cluster_y,
                        mode="markers+text",
                        marker=dict(
                            size=12,
                            color=color,
                            line=dict(width=2, color="white"),
                            opacity=0.8,
                        ),
                        text=cluster_names,
                        textposition="top center",
                        textfont=dict(size=10),
                        name=f"Cluster {cluster_id + 1}",
                        hovertemplate="<b>%{text}</b><br>Cluster: "
                        + f"{cluster_id + 1}<br>"
                        + "Coordonn√©es: (%{x:.2f}, %{y:.2f})<extra></extra>",
                    )
                )

            # Mise en forme du graphique
            fig_tsne.update_layout(
                title="Visualisation t-SNE des Ingr√©dients par Cluster",
                xaxis_title="Dimension t-SNE 1",
                yaxis_title="Dimension t-SNE 2",
                showlegend=True,
                height=600,
                hovermode="closest",
                plot_bgcolor="rgba(245,245,245,0.8)",
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            )

            # Afficher le graphique
            st.plotly_chart(fig_tsne, use_container_width=True)

            # Informations sur t-SNE
            with st.expander("‚ÑπÔ∏è √Ä propos de la visualisation t-SNE / Diagnostics"):
                st.markdown(
                    """
                **t-SNE (t-Distributed Stochastic Neighbor Embedding)** est une technique de r√©duction de dimensionnalit√©
                qui permet de visualiser des donn√©es haute-dimensionnelles en 2D.

                **Dans ce contexte :**
                - Chaque point repr√©sente un **ingr√©dient**
                - La position est bas√©e sur les **profils de co-occurrence** avec les autres ingr√©dients
                - Les couleurs correspondent aux **clusters K-means**
                - Les ingr√©dients proches ont des **patterns de co-occurrence similaires**

                **Interpr√©tation :**
                - Points regroup√©s = ingr√©dients utilis√©s dans des contextes similaires
                - Clusters color√©s = groupes d√©tect√©s par l'algorithme K-means
                - Distance = mesure de similarit√© des profils culinaires
                """
                )

                method = tsne_data.get("tsne_params", {}).get("method", "tsne")
                st.markdown(
                    f"""
                **Param√®tres & M√©thode :**
                - M√©thode effective : `{method}`
                - Perplexit√© (apr√®s ajustement) : {tsne_data['tsne_params']['perplexity']}
                - It√©rations max : {tsne_data['tsne_params']['max_iter']}
                - Seed al√©atoire : {tsne_data['tsne_params']['random_state']}
                - Ingr√©dients (n_samples) : {len(tsne_data['ingredient_names'])}
                """
                )

                if method != "tsne":
                    if method == "fallback_circle":
                        st.warning(
                            "Fallback circle layout utilis√© car t-SNE instable (trop peu d'ingr√©dients ou matrice d√©g√©n√©r√©e)."
                        )
                    elif method == "fallback_svd":
                        st.info("Projection issue de la d√©composition SVD (approximation PCA) suite √† un √©chec t-SNE.")

                # Afficher quelques stats basiques sur la dispersion
                try:
                    xs = tsne_data["x_coords"]
                    ys = tsne_data["y_coords"]
                    spread_x = max(xs) - min(xs)
                    spread_y = max(ys) - min(ys)
                    st.caption(f"Dispersion: Œîx={spread_x:.2f}, Œîy={spread_y:.2f} (√©chelle relative des clusters)")
                except Exception:
                    pass
        else:
            st.error("Erreur lors de la g√©n√©ration de la visualisation t-SNE")
            with st.expander("üõ† D√©tails de l'erreur"):
                st.json(tsne_data)
                st.markdown(
                    """
                **Causes possibles :**
                - Perplexit√© trop √©lev√©e par rapport au nombre d'ingr√©dients (doit √™tre < n_samples)
                - Matrice de co-occurrence vide ou d√©g√©n√©r√©e (toutes valeurs nulles)
                - Incoh√©rence entre le nombre de labels de clusters et la liste d'ingr√©dients
                - Conflit de cache sur des anciennes donn√©es

                **Actions sugg√©r√©es :**
                1. R√©duire le nombre d'ingr√©dients ou ajuster la perplexit√©
                2. Vider le cache (bouton Clear Cache) puis relancer
                3. V√©rifier que l'√©tape de clustering a bien √©t√© effectu√©e
                """
                )

    def render_sidebar_statistics(self, clusters: Optional[np.ndarray], ingredient_names: Optional[list[str]]) -> None:
        """Affiche les statistiques de clustering dans la sidebar.

        Pr√©sente des m√©triques r√©capitulatives et un graphique de r√©partition
        des ingr√©dients par cluster. N'affiche rien si les donn√©es ne sont pas
        disponibles.

        Args:
            clusters: Array numpy des labels de cluster, ou None si l'analyse
                n'a pas encore √©t√© effectu√©e.
            ingredient_names: Liste des noms d'ingr√©dients, ou None si l'analyse
                n'a pas encore √©t√© effectu√©e.

        Notes:
            Cette m√©thode v√©rifie que les deux param√®tres sont non-None avant
            d'afficher les statistiques. Le graphique utilise Plotly pour une
            visualisation interactive.
        """
        if clusters is not None and ingredient_names is not None:
            st.sidebar.markdown("---")
            st.sidebar.markdown("### üìä Statistiques")

            # Comptage par cluster
            cluster_counts = pd.Series(clusters).value_counts().sort_index()

            st.sidebar.metric("Total ingr√©dients", len(ingredient_names))
            st.sidebar.metric("Nombre de clusters", len(cluster_counts))

            # Graphique horizontal des proportions par cluster
            st.sidebar.markdown("**R√©partition par cluster:**")

            # Cr√©er le graphique avec Plotly
            colors = [
                "#FF6B6B",
                "#4ECDC4",
                "#45B7D1",
                "#96CEB4",
                "#FFEAA7",
                "#DDA0DD",
                "#98D8C8",
                "#F7DC6F",
                "#BB8FCE",
                "#85C1E9",
            ]

            fig = go.Figure()

            for i, count in enumerate(cluster_counts):
                percentage = (count / len(ingredient_names)) * 100
                color = colors[i % len(colors)]

                fig.add_trace(
                    go.Bar(
                        x=[count],
                        y=[f"Cluster {i + 1}"],
                        orientation="h",
                        name=f"Cluster {i + 1}",
                        marker_color=color,
                        text=f"{count} ({percentage:.1f}%)",
                        textposition="outside",
                        showlegend=False,
                    )
                )

            fig.update_layout(
                title="",
                xaxis_title="Nombre d'ingr√©dients",
                yaxis_title="",
                height=min(400, len(cluster_counts) * 40 + 100),
                margin=dict(l=10, r=10, t=10, b=10),
                font=dict(size=10),
            )

            st.sidebar.plotly_chart(fig, use_container_width=True)

    # ---------------- √âtapes de l'analyse ---------------- #

    def _render_step_1_preprocessing(self, analyzer: IngredientsAnalyzer) -> None:
        """Affiche l'√©tape 1 : Pr√©traitement NLP des ingr√©dients.

        Args:
            analyzer: Instance de l'analyseur contenant les r√©sultats du preprocessing.
        """
        st.markdown("---")
        st.header("üìà √âTAPE 1 : Pr√©traitement NLP des ingr√©dients")

        st.markdown(
            """
        **Question :** Comment normaliser et regrouper les variantes d'un m√™me ingr√©dient ?

        Les recettes utilisent des descriptions vari√©es pour un m√™me ingr√©dient (ex: "sel", "gros sel",
        "sel de mer", "sel fin"). Le pr√©traitement NLP vise √† identifier et regrouper ces variantes
        pour cr√©er une repr√©sentation coh√©rente.

        **M√©trique :** Taux de r√©duction du nombre d'ingr√©dients uniques apr√®s normalisation.
        """
        )

        # Afficher le r√©sum√© du preprocessing
        if hasattr(analyzer, "ingredient_groups") and analyzer.ingredient_groups:
            with st.expander("üîç D√©tails du pr√©traitement", expanded=True):
                # R√©cup√©rer les statistiques de traitement
                summary = analyzer.get_processing_summary()

                if "error" not in summary:
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric(
                            "Ingr√©dients bruts uniques",
                            f"{summary['normalization']['total_unique_raw']:,}",
                            help="Nombre d'ingr√©dients uniques avant normalisation",
                        )

                    with col2:
                        st.metric(
                            "Apr√®s normalisation",
                            f"{summary['normalization']['total_normalized']:,}",
                            delta=f"-{summary['normalization']['reduction_ratio']}%",
                            help="Nombre d'ingr√©dients apr√®s regroupement des variantes",
                        )

                    with col3:
                        st.metric(
                            "Groupes cr√©√©s",
                            f"{summary['grouping']['groups_with_multiple_items']}",
                            help="Nombre de groupes contenant plusieurs variantes",
                        )

                    # Exemples de normalisation
                    st.markdown("**üß™ Exemples de normalisation :**")
                    test_ingredients = [
                        "large eggs",
                        "fresh ground black pepper",
                        "unsalted butter",
                        "red onions",
                        "whole milk",
                        "extra virgin olive oil",
                    ]
                    for ing in test_ingredients:
                        normalized = analyzer.normalize_ingredient(ing)
                        st.write(f"‚Ä¢ `{ing}` ‚Üí `{normalized}`")

                    # Exemples de regroupements
                    multi_groups = [g for g in analyzer.ingredient_groups if len(g) > 1]
                    if multi_groups:
                        st.markdown("**üîó Exemples de regroupements d'ingr√©dients similaires :**")
                        for i, group in enumerate(multi_groups[:5]):
                            members_display = " | ".join(group[:5])
                            if len(group) > 5:
                                members_display += f" (+ {len(group) - 5} autres)"
                            st.write(f"**Groupe {i + 1}:** {members_display}")

        st.markdown(
            """
        **üí° Observations :** Le pr√©traitement NLP r√©duit significativement la redondance en identifiant
        les variantes linguistiques d'un m√™me ingr√©dient. Cette √©tape est cruciale pour obtenir une
        matrice de co-occurrence fiable.

        **üéØ Implication :** La normalisation permet de concentrer l'analyse sur les v√©ritables patterns
        culinaires plut√¥t que sur les variations de nomenclature.
        """
        )

    def _render_step_2_cooccurrence(self, ingredient_names: list[str], ingredients_matrix: pd.DataFrame) -> None:
        """Affiche l'√©tape 2 : Cr√©ation de la matrice de co-occurrence.

        Args:
            ingredient_names: Liste des noms d'ingr√©dients.
            ingredients_matrix: Matrice de co-occurrence.
        """
        st.markdown("---")
        st.header("üìà √âTAPE 2 : Matrice de co-occurrence")

        st.markdown(
            """
        **Objectif :** Quantifier la fr√©quence d'apparition conjointe de chaque paire d'ingr√©dients.

        La matrice de co-occurrence capture l'information fondamentale : combien de fois deux
        ingr√©dients apparaissent ensemble dans les recettes. Cette matrice sym√©trique constitue
        la base de notre analyse de similarit√©.

        **M√©thode :** Pour chaque recette, toutes les paires d'ingr√©dients pr√©sents sont comptabilis√©es.
        """
        )

        # Statistiques de la matrice
        total_cooccurrences = int(ingredients_matrix.values.sum() / 2)
        non_zero_pairs = int((ingredients_matrix.values > 0).sum() / 2)
        matrix_size = len(ingredient_names)
        max_possible_pairs = matrix_size * (matrix_size - 1) / 2
        sparsity = (1 - non_zero_pairs / max_possible_pairs) * 100

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Dimension matrice", f"{matrix_size}√ó{matrix_size}")
        with col2:
            st.metric("Co-occurrences totales", f"{total_cooccurrences:,}")
        with col3:
            st.metric("Paires non-nulles", f"{non_zero_pairs:,}")
        with col4:
            st.metric(
                "Sparsit√©",
                f"{sparsity:.1f}%",
                help="Pourcentage de paires sans co-occurrence",
            )

        st.markdown("---")

        # Analyse interactive de co-occurrence
        self.render_cooccurrence_analysis(ingredient_names, ingredients_matrix)

        st.markdown(
            """
        **üìä Ce que r√©v√®le la matrice :**

        La distribution des co-occurrences n'est pas uniforme. Certaines paires d'ingr√©dients
        apparaissent ensemble dans des milliers de recettes, r√©v√©lant des associations culinaires
        fortes.

        """
        )

    def _render_step_3_clustering(self, clusters: np.ndarray, ingredient_names: list[str], n_clusters: int) -> None:
        """Affiche l'√©tape 3 : Clustering K-means.

        Args:
            clusters: Array des labels de cluster.
            ingredient_names: Liste des noms d'ingr√©dients.
            n_clusters: Nombre de clusters cr√©√©s.
        """
        st.markdown("---")
        st.header("üìà √âTAPE 3 : Clustering K-means")

        st.markdown(
            f"""
        **Objectif :** Regrouper automatiquement les ingr√©dients en {n_clusters} familles distinctes.

        L'algorithme K-means partitionne les ingr√©dients en fonction de leurs profils de co-occurrence.
        Deux ingr√©dients dans le m√™me cluster partagent des contextes d'utilisation similaires, m√™me
        s'ils ne co-occurrent pas directement.

        **M√©thode :** K-means avec k={n_clusters}, distance euclidienne sur les vecteurs de co-occurrence.
        """
        )

        # Statistiques des clusters
        cluster_counts = pd.Series(clusters).value_counts().sort_index()

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Nombre de clusters", n_clusters)
        with col2:
            avg_size = len(ingredient_names) / n_clusters
            st.metric("Taille moyenne", f"{avg_size:.1f} ingr√©dients")
        with col3:
            largest_cluster_size = cluster_counts.max()
            st.metric("Plus grand cluster", f"{largest_cluster_size} ingr√©dients")

        st.markdown("---")

        # Affichage des clusters
        self.render_clusters(clusters, ingredient_names, n_clusters)

        st.markdown(
            f"""
        **üéØ Interpr√©tation des clusters :**

        Les clusters arrivent √† r√©v√©ler des "famille culinaire" d'ingr√©dients. Ils peuvent √™tre :
        - **Ingr√©dients pour patisserie**
        - **Produits de recettes sal√©s**

        **Limite m√©thodologique** : Le choix de k={n_clusters} est param√©trique. Diff√©rentes valeurs
        de k r√©v√®lent des structures √† diff√©rentes granularit√©s.
        De plus, les clusters ont tendance √† ne pas √™tre de la m√™me taille car une masse d'ingr√©dient √† faible co-occurence se regrouppent ensemble.
        """
        )

    def _render_step_4_visualization(self, analyzer: IngredientsAnalyzer, clusters: np.ndarray, tsne_perplexity: int) -> None:
        """Affiche l'√©tape 4 : Visualisation t-SNE 2D.

        Args:
            analyzer: Instance de l'analyseur.
            clusters: Array des labels de cluster.
            tsne_perplexity: Param√®tre de perplexit√© pour t-SNE.
        """
        st.markdown("---")
        st.header("üìà √âTAPE 4 : Visualisation t-SNE 2D")

        st.markdown(
            """
        **Objectif :** Projeter l'espace haute-dimensionnalit√© des co-occurrences en 2D pour exploration visuelle.

        La matrice de co-occurrence est un espace √† n dimensions (une par ingr√©dient). t-SNE
        (t-Distributed Stochastic Neighbor Embedding) r√©duit cette dimensionnalit√© √† 2D tout en
        pr√©servant les proximit√©s locales.

        **M√©thode :** t-SNE avec perplexit√©={}, optimisation par descente de gradient.
        """.format(
                tsne_perplexity
            )
        )

        # Visualisation t-SNE
        self.render_tsne_visualization(analyzer, clusters, tsne_perplexity)

        st.markdown(
            """
        **üîç Lecture de la visualisation :**

        - **Proximit√© spatiale** : Les ingr√©dients proches dans l'espace 2D ont des profils de
          co-occurrence similaires (utilis√©s dans des contextes culinaires similaires)
        - **Couleurs** : Chaque couleur repr√©sente un cluster K-means. La coh√©sion spatiale des
          couleurs valide la qualit√© du clustering
        - **Groupes isol√©s** : Les clusters bien s√©par√©s g√©ographiquement indiquent des familles
          culinaires distinctes

        **üí° Insights visuels :**

        La visualisation r√©v√®le souvent une structure non-lin√©aire de l'espace culinaire. Certains
        ingr√©dients "pont" peuvent se situer entre plusieurs clusters, refl√©tant leur polyvalence
        (ex: l'huile d'olive utilis√©e dans de multiples contextes, ou l'eau).

        **Validation du clustering** : Si les couleurs (clusters K-means) forment des groupes
        visuellement coh√©rents dans l'espace t-SNE, cela confirme que le clustering a captur√©
        des structures r√©elles plut√¥t qu'artificielles.

        **Limite de t-SNE** : La repr√©sentation 2D est approximative. Les distances absolues ne
        sont pas strictement pr√©serv√©es, seules les proximit√©s relatives comptent. Diff√©rentes
        ex√©cutions peuvent donner des configurations l√©g√®rement diff√©rentes (non-d√©terminisme).
        """
        )

    def _render_conclusion(self, ingredient_names: list[str], clusters: np.ndarray, n_clusters: int) -> None:
        """Affiche la conclusion de l'analyse.

        Args:
            ingredient_names: Liste des noms d'ingr√©dients.
            clusters: Array des labels de cluster.
            n_clusters: Nombre de clusters cr√©√©s.
        """
        st.markdown("---")
        st.subheader("üìã Conclusion de l'analyse")

        # Calculer quelques statistiques finales
        cluster_counts = pd.Series(clusters).value_counts()
        largest_cluster = cluster_counts.max()
        smallest_cluster = cluster_counts.min()

        st.markdown(
            f"""
        ### Synth√®se des r√©sultats

        **1. Pr√©traitement NLP r√©ussi :** La normalisation automatique a permis de r√©duire
        significativement la redondance des variantes d'ingr√©dients, cr√©ant une base solide
        pour l'analyse.

        **2. Structure r√©v√©l√©e par la co-occurrence :** L'analyse de {len(ingredient_names)}
        ingr√©dients a r√©v√©l√© des patterns clairs d'association culinaire, confirmant que la
        cuisine n'est pas al√©atoire.

        **3. Clustering coh√©rent :** L'algorithme K-means a identifi√© {n_clusters} familles
        d'ingr√©dients distinctes, avec des tailles variant de {smallest_cluster} √† {largest_cluster}
        ingr√©dients. Ces clusters essaye de capturer des insight sur le co-usage des ingr√©dients.

        **4. Validation visuelle :** La projection t-SNE montre la structure des clusters et
        l'organisation de l'espace culinaire.

        ### Applications pratiques

        Ces r√©sultats peuvent √™tre utilis√©s pour :
        - **Syst√®mes de recommandation** : Sugg√©rer des ingr√©dients compl√©mentaires lors de la
          cr√©ation de recettes
        - **Analyse nutritionnelle** : Identifier les associations alimentaires courantes pour
          des √©tudes di√©t√©tiques, nottament en reliant les informations caloriques
        - **Cr√©ativit√© culinaire** : D√©couvrir des combinaisons innovantes en explorant les
          fronti√®res entre clusters
        - **D√©tection d'anomalies** : Identifier des recettes avec des combinaisons inhabituelles

        ### Limites et perspectives

        **Limites :**
        - La co-occurrence ne capture pas l'ordre ou les quantit√©s des ingr√©dients
        - Les ingr√©dients tr√®s rares ne sont pas repr√©sent√©s et ceux trop pr√©sent
        peuvent √™tre mal repr√©sent√©s

        **Perspectives d'am√©lioration :**
        - Clustering hi√©rarchique pour r√©v√©ler plusieurs niveaux de granularit√©
        - Int√©gration d'informations s√©mantiques (cat√©gories nutritionnelles, origines)
        - Mod√®les de recommandation bas√©s sur les embeddings d'ingr√©dients
        """
        )

    def render_analysis_summary(self, analyzer: IngredientsAnalyzer) -> None:
        """Affiche le r√©sum√© d√©taill√© du processus d'analyse.

        Pr√©sente des informations sur le regroupement d'ingr√©dients similaires,
        la normalisation effectu√©e et des exemples de mappings. Utile pour
        comprendre les transformations appliqu√©es aux donn√©es brutes.

        Args:
            analyzer: Instance de l'analyseur contenant les r√©sultats du
                traitement (groupes d'ingr√©dients, mappings, etc.).

        Notes:
            Affiche plusieurs sections extensibles:
            - Exemples de regroupements d'ingr√©dients similaires
            - Debug de la normalisation pour des ingr√©dients courants
            - Tests de normalisation en temps r√©el
            - R√©sum√© complet du pipeline de traitement
        """
        # Afficher quelques exemples de regroupements d'ingr√©dients
        if hasattr(analyzer, "ingredient_groups") and analyzer.ingredient_groups:
            with st.expander("üîó Exemples de regroupements d'ingr√©dients similaires"):
                # Afficher les groupes avec plus d'un √©l√©ment
                multi_groups = [g for g in analyzer.ingredient_groups if len(g) > 1]

                if multi_groups:
                    # Afficher les 10 premiers groupes
                    for i, group in enumerate(multi_groups[:10]):
                        members_display = " | ".join(group[:5])
                        if len(group) > 5:
                            members_display += f" (+ {len(group) - 5} autres)"
                        st.write(f"**Groupe {i + 1}:** {members_display}")

                    st.info(f"Total: {len(multi_groups)} groupes d'ingr√©dients similaires d√©tect√©s")

                    # Debug pour des ingr√©dients probl√©matiques
                    debug_info = analyzer.debug_ingredient_mapping(["pepper", "egg", "salt", "butter", "onion"])
                    if "search_results" in debug_info:
                        st.write("**üîç Debug - Exemples de normalisation:**")
                        for term, matches in debug_info["search_results"].items():
                            if matches:
                                st.write(f"*{term.title()}:*")
                                for match in matches[:3]:  # Limiter √† 3 r√©sultats
                                    # Montrer aussi la normalisation
                                    normalized = analyzer.normalize_ingredient(match["ingredient"])
                                    status = (
                                        "‚úÖ Repr√©sentant"
                                        if match["is_representative"]
                                        else f"‚û°Ô∏è Mapp√© vers '{match['representative']}'"
                                    )
                                    st.write(
                                        f"  ‚Ä¢ `{match['ingredient']}` ‚Üí `{normalized}` {status}"
                                    )

                    # Exemple de normalisation en temps r√©el
                    st.write("**üß™ Test de normalisation:**")
                    test_ingredients = [
                        "large eggs",
                        "fresh ground black pepper",
                        "unsalted butter",
                        "red onions",
                        "whole milk",
                        "extra virgin olive oil",
                    ]
                    for ing in test_ingredients:
                        normalized = analyzer.normalize_ingredient(ing)
                        st.write(f"‚Ä¢ `{ing}` ‚Üí `{normalized}`")

                    # R√©sum√© complet du processus
                    with st.expander("üìã R√©sum√© Complet du Data Processing"):
                        summary = analyzer.get_processing_summary()
                        if "error" not in summary:
                            col1, col2 = st.columns(2)

                            with col1:
                                st.write("**üìä Donn√©es d'entr√©e:**")
                                st.write(
                                    f"‚Ä¢ Recettes: {
                                        summary['input_data']['total_recipes']:,}"
                                )
                                st.write(
                                    f"‚Ä¢ Ingr√©dients bruts: {
                                        summary['input_data']['total_raw_ingredients']:,}"
                                )
                                st.write(
                                    f"‚Ä¢ Moyenne par recette: {
                                        summary['input_data']['avg_ingredients_per_recipe']}"
                                )

                                st.write("**üîÑ Normalisation:**")
                                st.write(
                                    f"‚Ä¢ Ingr√©dients uniques bruts: {
                                        summary['normalization']['total_unique_raw']:,}"
                                )
                                st.write(
                                    f"‚Ä¢ Apr√®s normalisation: {
                                        summary['normalization']['total_normalized']:,}"
                                )
                                st.write(
                                    f"‚Ä¢ R√©duction: {
                                        summary['normalization']['reduction_ratio']}%"
                                )

                            with col2:
                                st.write("**üîó Regroupement:**")
                                st.write(
                                    f"‚Ä¢ Groupes multiples: {
                                        summary['grouping']['groups_with_multiple_items']}"
                                )
                                st.write(
                                    f"‚Ä¢ Plus grand groupe: {
                                        summary['grouping']['largest_group_size']} √©l√©ments"
                                )

                                st.write("**üìà Matrice Co-occurrence:**")
                                st.write(
                                    f"‚Ä¢ Dimensions: {
                                        summary['cooccurrence_matrix']['dimensions']}"
                                )
                                st.write(f"‚Ä¢ Co-occurrences: {summary['cooccurrence_matrix']['total_cooccurrences']:,}")
                                st.write(f"‚Ä¢ Paires non-nulles: {summary['cooccurrence_matrix']['non_zero_pairs']:,}")
                                st.write(
                                    f"‚Ä¢ Sparsit√©: {
                                        summary['cooccurrence_matrix']['sparsity']}%"
                                )
                else:
                    st.warning("Aucun regroupement d√©tect√©. Tous les ingr√©dients sont consid√©r√©s comme uniques.")

    def run(self) -> None:
        """Point d'entr√©e principal de la page.

        Orchestre l'ensemble du workflow de la page de clustering:
        1. Chargement automatique des donn√©es
        2. Affichage de la sidebar avec param√®tres
        3. Ex√©cution de l'analyse (process, clustering, visualisation)
        4. Affichage des r√©sultats interactifs

        Cette m√©thode g√®re √©galement le cache de session Streamlit pour
        persister les r√©sultats entre les interactions utilisateur.

        Raises:
            Exception: Affiche les erreurs via st.error mais ne les propage pas
                pour maintenir l'interface fonctionnelle.
        """
        self.logger.info("Starting ingredients clustering analysis")

        # Introduction et User Story
        with st.expander("üéØ Objectifs et m√©thodologie de l'analyse", expanded=True):
            st.markdown(
                """
            ### Peut-on regrouper les ingr√©dients selon leurs usages culinaires‚ÄØ?

            Cette analyse explore les patterns de co-occurrence d'ingr√©dients dans les recettes pour
            identifier les associations culinaires naturelles. En analysant des milliers de recettes,
            nous r√©v√©lons les combinaisons d'ingr√©dients qui apparaissent fr√©quemment ensemble.

            **Questions centrales :** Quels ingr√©dients sont naturellement associ√©s ? Existe-t-il des
            familles d'ingr√©dients distinctes ? Comment les ingr√©dients se regroupent-ils en fonction
            de leurs profils d'utilisation ?

            **Approche :** Analyse NLP des listes d'ingr√©dients, construction d'une matrice de
            co-occurrence, clustering automatique par K-means, et visualisation en 2D par t-SNE.

            **Probl√©matique :** Dans un espace culinaire o√π des milliers d'ingr√©dients peuvent √™tre
            combin√©s, comment identifier automatiquement les groupes d'ingr√©dients qui partagent des
            contextes d'utilisation similaires ?
            """
            )

        # Sidebar pour les param√®tres
        params = self.render_sidebar()
        self.logger.debug(f"Clustering parameters: {params}")

        # Chargement automatique des donn√©es
        self.logger.debug("Loading and preparing data")
        data = self._load_and_prepare_data()

        # Traitement des donn√©es
        if data is not None:
            self.logger.info(f"Dataset loaded successfully: {len(data)} recipes")

            # Initialisation de l'analyseur
            analyzer = IngredientsAnalyzer(data)

            # Cache controls dans la sidebar
            self._render_cache_controls(analyzer)

            # V√©rifier si les param√®tres ont chang√©
            params_changed = False
            if "last_params" in st.session_state:
                last_params = st.session_state["last_params"]
                if (
                    last_params["n_ingredients"] != params["n_ingredients"]
                    or last_params["n_clusters"] != params["n_clusters"]
                    or last_params["tsne_perplexity"] != params["tsne_perplexity"]
                ):
                    params_changed = True

            # Lancer l'analyse si bouton cliqu√©, premi√®re fois, ou param√®tres chang√©s
            should_analyze = params["analyze_button"] or "ingredient_names" not in st.session_state or params_changed

            if should_analyze:
                self.logger.info(
                    f"Starting clustering analysis with parameters: n_ingredients={
                        params['n_ingredients']}, n_clusters={
                        params['n_clusters']}"
                )
                with st.spinner("Analyse en cours..."):
                    # Traitement des ingr√©dients
                    self.logger.debug(
                        f"Processing ingredients with n_ingredients={
                            params['n_ingredients']}"
                    )
                    ingredients_matrix, ingredient_names = analyzer.process_ingredients(params["n_ingredients"])
                    self.logger.info(f"Processed ingredients matrix: {ingredients_matrix.shape}")

                    # Clustering
                    self.logger.debug(f"Performing clustering with n_clusters={params['n_clusters']}")
                    clusters = analyzer.perform_clustering(ingredients_matrix, params["n_clusters"])
                    self.logger.info(f"Clustering completed: {len(set(clusters))} unique clusters found")

                    # Sauvegarde des r√©sultats dans la session
                    st.session_state["ingredient_names"] = ingredient_names
                    st.session_state["clusters"] = clusters
                    st.session_state["ingredients_matrix"] = ingredients_matrix
                    st.session_state["analyzer"] = analyzer
                    st.session_state["last_params"] = params.copy()

            # Affichage des r√©sultats si disponibles
            if "ingredient_names" in st.session_state:
                self.logger.debug("Displaying cached clustering results")
                ingredient_names = st.session_state["ingredient_names"]
                ingredients_matrix = st.session_state["ingredients_matrix"]
                clusters = st.session_state["clusters"]
                analyzer = st.session_state["analyzer"]

                # Statistiques g√©n√©rales
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üìä Recettes analys√©es", f"{len(data):,}")
                with col2:
                    st.metric("ü•ò Ingr√©dients retenus", f"{len(ingredient_names)}")
                with col3:
                    st.metric("üéØ Clusters cr√©√©s", f"{params['n_clusters']}")

                # √âTAPE 1 : Pr√©traitement NLP
                self._render_step_1_preprocessing(analyzer)

                # √âTAPE 2 : Matrice de co-occurrence
                self._render_step_2_cooccurrence(ingredient_names, ingredients_matrix)

                # √âTAPE 3 : Clustering
                self._render_step_3_clustering(clusters, ingredient_names, params["n_clusters"])

                # √âTAPE 4 : Visualisation t-SNE
                self._render_step_4_visualization(analyzer, clusters, params["tsne_perplexity"])

                # Conclusion
                self._render_conclusion(ingredient_names, clusters, params["n_clusters"])

                # Statistiques dans la sidebar
                self.render_sidebar_statistics(clusters, ingredient_names)

        else:
            st.error("Impossible de charger les donn√©es. V√©rifiez la pr√©sence du fichier de donn√©es.")

        # Footer
        st.markdown("---")
        st.caption(
            "üí° **Configuration** : Ajustez les param√®tres dans la sidebar pour explorer diff√©rentes configurations de clustering."
        )
